---
lecture_num: 4

reveal:
    history: true
    slideNumber: true
---

<section>
    <h2>House-keeping</h2>

    <ol class="spaced" style="margin-top:10%">
        <li>Lab this Friday. Details to be announced.</li>
        <li>Assignment 1 will be <b>available on Canvas this afternoon</b>.</li>
        <li>My office is room 467 (fourth floor) of building 303S (in the CS department)</li>
        <li>Office hours:
            <ul>
                <li>1-3pm, Wednesday</li>
                <li>Almost any other time, but ...</li>
                <li>Email <a href="mailto:tgvaughan@gmail.com">tgvaughan@gmail.com</a> to avoid dissapointment.</li>
            </ul>
        </li>
    </ol>
</section>

<section>
    <section class="center">
        <h2>Hidden Markov Models (HMMs)</h2>
    </section>

    <section>
        <h3>Markov Chains</h3>

        <ul class="spaced" style="margin-top:2em">
            <li>Markov Chains are discrete stochastic processes which obey the Makov property:

                <blockquote>
                    $$P(X_{i}|X_{i-1},X_{i-2},\ldots,X_0) = P(X_i|X_{i-1})$$
                </blockquote>
            </li>

            <li>The index $i$ is often interpreted as "time", but it need not be.</li>

            <li>Homogeneous Markov chains satisfy the additional requirement:
                <blockquote>
                    $$P(X_{i+1}=y|X_{i}=x)=P(X_i=y|X_{i-1}=x)$$
                </blockquote>
            </li>
            <li>This allows the vector $\vec{P}_i$ of probabilities at $i$ to be expressed as
                $$\vec{P}_i=M\vec{P}_{i-1}=M^i\vec{P}_{0}$$
                where $M$ is the matrix of <b>transition probailities</b>.</li>
        </ul>

    </section>

    <section>
        <h3>Markov Chains as Finite State Machines</h3>

        <p>Homogeneous Markov chains can be represented as finite state machines.</p>

        <img data-src="DNA_FSM.svg" style="width:50%">

        <p>Arrows can be labeled with transition probabilities to complete the description.</p>
    </section>

    <section>
        <h3>Modelling begin and end states</h3>

        <p>Including the begin and end states explicitly allows the length of
        the chain to be modelled.</p>

        <img data-src="DNA_FSM_BE.svg" style="width:60%">

        <p>If the transition probabilities to the end state are uniform, i.e.
        $M_{x\mathcal{E}}=p~~\forall x$ then the length has a geometric distribution:</p>
        $$P(L=l)=P(X_{l+1}=\mathcal{E})=(1-p)^{l}p$$
    </section>

    <section>
        <h3>Markov Chains with hidden state</h3>

        <ul class="spaced" style="margin-top:10%">
            <li>For HMMs, observations are tied to states probabilistically.</li>
            <li>Consider $Y_1,Y_2,\ldots,Y_N$ to be the sequence of hidden states
                evolving according to the transition probability matrix $M$.</li>
            <li>Observations $X_1,X_2,\ldots,X_N$ are each drawn from $P(X_i|Y_i)$.</li>
            <li>Assuming homogeneity lets us define
                $$P(X_i=x|Y_i=y) =e_y(x)$$
                to be the <b>emission probability</b>.</li>
        </ul>
    </section>

    <section>
        <h3>HMM example: occasionally dishonest casino</h3>

        <img data-src="HT_HMM.svg" style="width:60%">

        <div class="textbox">
            <div class="title"><a id="HMMsim" href="#" style="color:white">Run Demo</a></div>
            <pre id="HMMsim_output">

            </pre>
        </div>
    </section>
</section>

<section>
    <section class="center">
        <h2>Finding optimal paths</h2>
    </section>

    <section>
        <h3>Most probable paths</h3>

        <p>The most probable path $\vec{Y}$ through the hidden state space is:</p>

        \begin{align*}
        \vec{Y}^* &amp;= \underset{\vec{Y}}{\text{argmax}}~P(\vec{Y}|\vec{X})\\
        &amp; = \underset{\vec{Y}}{\text{argmax}}~\frac{P(\vec{Y},\vec{X})}{P(\vec{X})}\\
        &amp; = \underset{\vec{Y}}{\text{argmax}}~P(\vec{Y},\vec{X})
        \end{align*}

        <ul>
            <li>Question: Many possible paths!! How do we find the best one?</li>
            <li>Answer: Dynamic Programming!</li>
        </ul>

        <p>Define $v_k(i)$ as the joint probability of the most probable (sub) path ending with
        observation number $i$ in state $k$.  If this is known for all states $k$, can compute:</p>
        $$v_l(i+1) = e_l(x_{i+1})\max_{k}(v_k(i)M_{kl})$$

        <blockquote>
            Optimal substructure!
        </blockquote>
    </section>

    <section>
        <h3>Why "Dynamic Programming"?</h3>

        <blockquote style="width:90%; margin-top: 2em; font-size:0.7em">
            The 1950s were not good years for mathematical research. We
            had a very interesting gentleman in Washington named Wilson. He was
            Secretary of Defense, and he actually had a pathological fear and
            hatred of the word research. I’m not using the term lightly; I’m using
            it precisely. His face would suffuse, he would turn red, and he would
            get violent if people used the term research in his presence. You can
            imagine how he felt, then, about the term mathematical. The RAND
            Corporation was employed by the Air Force, and the Air Force had Wilson
            as its boss, essentially. Hence, I felt I had to do something to shield
            Wilson and the Air Force from the fact that I was really doing
            mathematics inside the RAND Corporation. What title, what name, could I
            choose? In the first place I was interested in planning, in decision
            making, in thinking. But planning, is not a good word for various
            reasons. I decided therefore to use the word “programming”. I wanted to
            get across the idea that this was dynamic, this was multistage, this
            was time-varying. I thought, let's kill two birds with one stone. Let's
            take a word that has an absolutely precise meaning, namely dynamic, in
            the classical physical sense. It also has a very interesting property
            as an adjective, and that it's impossible to use the word dynamic in a
            pejorative sense. Try thinking of some combination that will possibly
            give it a pejorative meaning. It's impossible. Thus, I thought dynamic
            programming was a good name. It was something not even a Congressman
            could object to.

            <div class="cite">Richard Bellman, "Eye of the Hurricane: An Autobiography", 1984</div>
        </blockquote>
    </section>

    <section>
        <h3>Viterbi Algorithm</h3>

        <div class="textbox" style="width:70%;margin-left:15%;margin-top:10%">
            <dl>
                <dt>Initialization ($i=0$):</dt><dd>
                $v_{k}(0) = \delta_{k,k_0}$ where $k_0=\underset{k}{\text{argmax}}~P(Y_0=k)$
                </dd>
                <dt>Recursion ($i = 1\ldots L$):</dt><dd></dd>
                $$v_l(i) = e_l(x_i)\max_{k}(v_k(i-1)M_{kl})$$
                $$\text{ptr}_i(l) = \underset{k}{\text{argmax}}(v_k(i-1)M_{kl})$$
                <dt>Termination:</dt><dd>
                $$P(\vec{X},\vec{Y}^*) = \max_k(v_k(L))$$
                $$Y^*_L = \underset{k}{\text{argmax}}(v_k(L))$$
                </dd>
                <dt>Traceback ($i = L\ldots 1$):</dt><dd>
                $$Y^*_{i-1} = \text{ptr}_i(Y^*_i)$$
                </dd>
            </dl>
        </div>

        <p>(Optimal path through network whiteboard example.)</p>

    </section>

    <section>
        <h3>Detecting coin fairness</h3>

        <div class="textbox" style="margin-top:20%">
            <div class="title"><a id="HMMviterbi" href="#" style="color:white">Run Viterbi Demo</a></div>
            <pre id="HMMviterbi_output">


            </pre>
        </div>
    </section>
</section>

<section>
    <section class="center">
        <h2>Computing Probabilities</h2>
    </section>

    <section>
        <h2>Forward Algorithm</h2>

        <p>This algorithm computes the probability of the sequence of observations given the model.<br>
        It is trivial to derive.</p>

        <p>Define $f_k(i) = P(X_1,\ldots,X_i,Y_i=k)$.</p>

        <div class="textbox" style="width:70%;margin-left:15%;">
            <dl class="spaced">
                <dt>Initialization</dt><dd> $$f_k(0) = P(Y_0=k)$$ </dd>
                <dt>Recursion ($i=1\ldots L$)</dt>
                <dd>$$f_l(i) = e_l(x_i)\sum_k f_k(i-1)M_{kl}$$</dd>
                <dt>Termination</dt>
                <dd>$P(\vec{X})=\sum_k f_k(L)$</dd>
            </dl>
        </div>

    </section>

    <section>
        <h2>Posterior state probabilities</h2>

        <p>It is interesting to know the posterior probability of hidden states at each site.</p>
        <blockquote>
            This is <b>NOT</b> the posterior distribution over paths. Stringing together the
            most probable states may not even produce a valid path!
        </blockquote>

        <p>Start by considering:<p>
        \begin{align*}
        P(\vec{X}, Y_i=k) &amp;= P(X_1,\ldots,X_i,Y_i=k)P(X_{i+1},\ldots,X_L|X_1,\ldots,X_{i},Y_i=k)\\
        &amp; = P(X_1,\ldots,X_i,Y_i=k)P(X_{i+1},\ldots,X_L|Y_i=k)\\
        &amp; \equiv f_k(i) b_k(i)
        \end{align*}

        <p>Use a similar recursion to the forward algorithm to find $b_k(i)$.</p>

        <p>Then $$P(Y_i=k|\vec{X}) = \frac{f_k(i)b_k(i)}{P(\vec{X})}$$ where
        $P(\vec{X})$ is computed using either the forward or backward
        algorithms.</p>
    </section>

    <section>
        <h2>Backward Algorithm</h2>

        <p>This algorithm implements the recursion required to compute $b_k(i)$</p>

        <p>Define $b_k(i) = P(X_{i+1},\ldots,X_L|Y_i=k)$.</p>

        <div class="textbox" style="width:70%;margin-left:15%;">
            <dl class="spaced">
                <dt>Initialization</dt><dd> $$b_k(L+1) = 1$$</dd>
                <dt>Recursion ($i=L-1\ldots 1$)</dt>
                <dd>$$b_l(i) = \sum_k M_{lk}e_k(x_{i+1})b_k(i+1)$$</dd>
                <dt>Termination</dt>
                <dd>$P(\vec{X})=\sum_k P(Y_1=k)e_k(x_1)b_k(1)$</dd>
            </dl>
        </div>
    </section>

    <section>
        <h2>Posterior fairness probabilities</h2>

        <div class="textbox" style="margin-top:2em">
            <div class="title"><a id="HMMforwardBackward" href="#" style="color:white">Run Forward-Backward Demo</a></div>
            <pre id="HMMforwardBackwardOutput">
























            </pre>
        </div>

    </section>
</section>

<section>
    <section class="center">
        <h2>Parameter inference</h2>
    </section>

    <section>
        <h3>Known state trajectory</h3>

        <p style="margin-top:10%">When the hidden state trajectory $\vec{Y}$ is known, can use the
        following estimators for the transition and emission probabilities:

        $$M_{kl} = \frac{A_{kl}}{\sum_{l'}A_{kl'}}$$

        where $\mathcal{A}_{kl}$ are the number of transitions between states
        $k$ and $l$ on the trajectory.</p>

        <p>Similarly,
        $$e_{k}(x) = \frac{E_{k}(x)}{\sum_{k'}E_{k'}(x)}$$
        where $E_k(x)$ is the number of emissions of $x$ from state $k$.</p>

        <p>These are maximum likelihood (point) estimates. Can use <i>pseudo-count</i> offsets to
        avoid problems due to overfitting and insufficient data.</p>
        
    </section>

    <section>
        <h3>Unknown hidden states: Baum-Welch Algorithm</h3>

        <div class="textbox">
            <dl>
                <dt>Initialization</dt><dd>Pick arbitrary model parameters.</dd>
                <dt>Iterate</dt><dd>
                <ol>
                    <li>Set $A$ and $E$ to their pseudo-count values.</li>
                    <li>For each training sequence $\vec{X}^j$:
                        <ol>
                            <li>Calculate $f_k(i)$ for $\vec{X}^j$ using forward algorithm</li>
                            <li>Calculate $b_k(i)$ for $\vec{X}^j$ using backward algorithm</li>
                            <li>Add the contribution of $j$ to $A$ and $E$ using equations below.</li>
                        </ol>
                    </li>
                    <li>Update values for $M$ and $e$ based on ML estimates.</li>
                    <li>Compute likelihood of new model.</li>
                    <li>If change in likelihood is "small enough", stop.</li>
                </dd>
            </dl>

            <br>

        $$\langle A_{kl}\rangle = \sum_j\frac{1}{P(\vec{X}^j)}\sum_i f_k^j(i)M_{kl}e_l(x^{j}_{i+1})b^j_l(i+1)$$

        $$\langle E_k(x)\rangle = \sum_j\frac{1}{P(\vec{X}^j)}\sum_{i \text{ s.t. } X^j_i=x}f_k^j(i)b_k^j(i)$$

        </div>

    </section>
</section>

<section>
    <section class="center">
        <h2>HMMs in Bioinformatics</h2>
    </section>

    <section>
        <h3>Pairwise alignment with HMMs</h3>

        <img data-src="pair_HMM.svg" style="width:80%">
    </section>

    <section>
        <h3>Most likely pairwise alignment</h3>

        <div class="textbox">
            <div class="title">Viterbi algorithm for pair HMMs</div>

            <dl class="spaced">
                <dt>Initialization</dt><dd>
                $v_M(0,0)=1$, $v_X(0,0) = v_Y(0,0) = 0$<br>
                $v_k(i,-1)=v_k(-1,j)=v_k(i,0)=v_k(0,j)=0$
                </dd>
                <dt>Recurrence:</dt><dd>
                \begin{align*}
                v_M(i,j) &amp;= p_{x_iy_j}\max\left\{\begin{array}{l}
                (1-2\delta-\tau)v_M(i-1,j-1)\\
                (1-\epsilon-\tau)v_X(i-1,j-1)\\
                (1-\epsilon-\tau)v_Y(i-1,j-1)
                \end{array}\right.\\

                v_X(i,j) &amp; = q_{x_i}\max\left\{\begin{array}{l}
                \delta v_M(i-1,j)\\
                \epsilon v_X(i-1,j);
                \end{array}\right.\\

                v_Y(i,j) &amp; = q_{y_i}\max\left\{\begin{array}{l}
                \delta v_M(i,j-1)\\
                \epsilon v_X(i,j-1);
                \end{array}\right.

                \end{align*}
                </dd>
                <dt>Termination:</dt><dd>
                $v_E=\tau\max(v_M(n,m), v_X(n,m), v_Y(n,m))$
                </dd>
            </dl>
        </div>
    </section>

    <section>
        <h3>Log-odds formulation</h3>

        <p>Can produce 
    </section>

    <section>
        <h3>Pairwise alignment probabilities</h3>
    </section>

    <section>
        <h3>Profile alignment with HMMs</h3>
    </section>
</section>

<section>
    <h2>Summary</h2>
</section>

